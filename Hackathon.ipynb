{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hackathon",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cedric979/HACKATHON1/blob/main/Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w0_1rG6r7xC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkWqw-qggJPK",
        "outputId": "d4243109-e857-4589-a211-a8b72c346e29"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdWwZqw9gzjd"
      },
      "source": [
        "#df_lyrics = pd.read_csv('/content/drive/MyDrive/df_lyrics_final.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDykwBuVwgQ9"
      },
      "source": [
        "df_lyrics = pd.read_csv('/content/lyrics-data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6FIrbNd-wrug",
        "outputId": "b503bd5a-e3af-478d-f968-0f557dea0c57"
      },
      "source": [
        "df_lyrics.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ALink</th>\n",
              "      <th>SName</th>\n",
              "      <th>SLink</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>Idiom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/10000-maniacs/</td>\n",
              "      <td>More Than This</td>\n",
              "      <td>/10000-maniacs/more-than-this.html</td>\n",
              "      <td>I could feel at the time. There was no way of ...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/10000-maniacs/</td>\n",
              "      <td>Because The Night</td>\n",
              "      <td>/10000-maniacs/because-the-night.html</td>\n",
              "      <td>Take me now, baby, here as I am. Hold me close...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/10000-maniacs/</td>\n",
              "      <td>These Are Days</td>\n",
              "      <td>/10000-maniacs/these-are-days.html</td>\n",
              "      <td>These are. These are days you'll remember. Nev...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/10000-maniacs/</td>\n",
              "      <td>A Campfire Song</td>\n",
              "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
              "      <td>A lie to say, \"O my mountain has coal veins an...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/10000-maniacs/</td>\n",
              "      <td>Everyday Is Like Sunday</td>\n",
              "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
              "      <td>Trudging slowly over wet sand. Back to the ben...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ALink  ...    Idiom\n",
              "0  /10000-maniacs/  ...  ENGLISH\n",
              "1  /10000-maniacs/  ...  ENGLISH\n",
              "2  /10000-maniacs/  ...  ENGLISH\n",
              "3  /10000-maniacs/  ...  ENGLISH\n",
              "4  /10000-maniacs/  ...  ENGLISH\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E7uqonl0CJY"
      },
      "source": [
        "# **Taking care of missing values, filling Nan with missing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbXnJHoU4wnu",
        "outputId": "b28ef357-a86e-494e-c650-0d8433888412"
      },
      "source": [
        "df_lyrics.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 209522 entries, 0 to 209521\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   ALink   209522 non-null  object\n",
            " 1   SName   209522 non-null  object\n",
            " 2   SLink   209522 non-null  object\n",
            " 3   Lyric   209484 non-null  object\n",
            " 4   Idiom   206375 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 8.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNsTN_C646zS",
        "outputId": "0f8c810f-683a-4f8e-bd14-1edac8394197"
      },
      "source": [
        "df_lyrics['ALink'].value_counts(dropna = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/chris-brown/          1176\n",
              "/elvis-presley/         784\n",
              "/glee/                  716\n",
              "/akon/                  660\n",
              "/elton-john/            651\n",
              "                       ... \n",
              "/mc-kill/                 1\n",
              "/guilherme-e-renan/       1\n",
              "/junior-soares/           1\n",
              "/caput/                   1\n",
              "/nilton-areas/            1\n",
              "Name: ALink, Length: 2993, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eOSJq8W5COP",
        "outputId": "5af4a3f7-4351-4f74-a12f-b66052e02071"
      },
      "source": [
        "df_lyrics['SName'].value_counts(dropna = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Intro                              80\n",
              "Saudade                            69\n",
              "Home                               61\n",
              "Angel                              60\n",
              "Hold On                            53\n",
              "                                   ..\n",
              "Marcy Me                            1\n",
              "Quando Eu Te Amar                   1\n",
              "Küss Mich (Fellfrosch) (inglês)     1\n",
              "Choro de Alegria                    1\n",
              "I'm Gonna Bid My Blues Goodbye      1\n",
              "Name: SName, Length: 128083, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeGFvsLz5EFE",
        "outputId": "aef94c34-d7ca-4bf8-b6be-720a8be0b41e"
      },
      "source": [
        "df_lyrics['SLink'].value_counts(dropna = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/m-i-a/pull-up-the-people.html               6\n",
              "/m-i-a/bucky-done-gun.html                   6\n",
              "/m-i-a/can-see-can-do.html                   6\n",
              "/edu-gueda/tentando-a-sorte.html             6\n",
              "/edu-gueda/elas-part-thaeme-e-thiago.html    6\n",
              "                                            ..\n",
              "/t-a-t-u/vsya-moya-lyubov.html               1\n",
              "/morrissey/boxers.html                       1\n",
              "/raca-negra/estou-mal.html                   1\n",
              "/lady-gaga/changing-skies.html               1\n",
              "/romero/eu-fico-feliz.html                   1\n",
              "Name: SLink, Length: 167499, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ3CmvZo5GxG",
        "outputId": "30b893fe-f59d-42a7-fecc-fd02264fb543"
      },
      "source": [
        "df_lyrics.dropna(axis = 0, inplace = True, subset =['Lyric'])\n",
        "df_lyrics['Lyric'].value_counts(dropna = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Instrumental                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         592\n",
              "instrumental                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         265\n",
              "[Instrumental]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        66\n",
              "(Instrumental)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        66\n",
              "(instrumental)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        41\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ... \n",
              "I never even thought that you would leave me. I hated the words that I couldn't love you. But you have to go to a place. Where you can't come back where I can't see you. What can I do?. *Even though I'm leaving you there. Even though I can't ever see you again. I know that you are the one that. I believe in my life. Even though my heart left yours... But I hope that your image will still remain in me. Even if you completely change my love will still be you. But if I can't see your image, can't see you. I don't have any courage to do so. But you have to go to a place. Where you can't come back where I can't see you. What can I do?. repeat *. I beg you to forget me and live your life. I don't have any courage to do that myself. I hope that you won't be in pain because of me. I'm leaving you here like my heart. Even though I can't ever see you again. I know that you are the one that. I believe in my life. I hope you don't know how I feel right now... repeat *                                                                                                                                                                                                                                                                                                                                                             1\n",
              "When I had you to myself. I didn't want you around. Those pretty faces always made you stand out in a crowd. But someone picked you from the bunch. when glance was all it took. Now it's much too late for me to take a second look. Oh baby give me one more chance. (show you that I love you). Won't you please let me. (back to your heart). Oh darlin' I was blind to let you go. (let you go baby). But now since I see you in his arms. (I want you back). Yes I do now. (I want you back). Ooh ooh baby. (I want you back). Yeah yeah yeah yeah.... (I want you back). Na na na na. I want you back!. (...). When we played tag in grade school. You wanted to be It. But chasing boys was just a fad. You crossed your heart you'd quit. When we grew up you traded. Your promise for my ring. Now just like back to grade school. You're doing the same old thing!. Stop! The love you save may be your own!. Darling, take it slow. Or some day you'll be all alone. You'd better stop the love you save may be your own!. Darling, look both ways before you cross me. You're headed for the danger zone. Slow down. Slow down. Slow down. Slow down                                                                                                                                                                                                      1\n",
              "And you say this ain’t living. You say you can’t go on. Only take as you’re given. And now your hope is all but gone (yeah). Though you lost your way (now is not forever). But I know your pain. We all fall sometimes, you’re not the first. But I know it hurts. Yeah, I know it hurts. In the end you’ll find what you deserve. Still I know it hurts. Yeah, I know it hurts. Oh ohhh... hoh oh…. And the tide’s only rising. The storm is on it’s way - yeah. But you can’t keep on fighting. So bitter worn and so afraid. Though it’s sad and wrong. I hope you will remember, oh oh oh. You must carry on. We all fall sometimes, you’re not the first. But I know it hurts. Yeah, I know it hurts. In the end you’ll find what you deserve. Still I know it hurts. Yeah, I know it hurts. Eahh… eah… eah eah…. There’s still tomorrow. Hold on, hold on. There’s still tomorrow. Just wait, just wait. There’s still tomorrow. Hold on…. Hold on…. We all fall sometimes, you’re not the first. But I know it hurts. Yeah, I know it hurts. In the end you’ll find what you deserve. Still I know it hurts. Yeah, I know it hurts. Solo                                                                                                                                                                                                                       1\n",
              "Quanto mais o tempo passa. Eu vejo não vai ter graça. De viver sem ter você no meu coração. Cada dia o meu amor aumenta. Não aguento ficar um minuto sem você. Pra mim já é loucura total. Te desejo mais que tudo. Nosso amor é maior que o mundo. E só deus pode explicar. Pequenos detalhes que eu não consigo entender. Como pode uma coisa tão linda existir entre eu e você. Teu amor me pegou e não vou te deixar por nada. (refrão). Amor eu vou me declarar. Você é tudo que eu sempre quis. Eu quero acordar de manhã do teu lado e dizer. Que eu sou o homem mais feliz. (refrão). Te desejo mais que tudo. Nosso amor é maior que o mundo. E só deus pode explicar. Pequenos detalhes que eu não consigo entender. Como pode uma coisa tão linda existir entre eu e você. Teu amor me pegou e não vou te deixar por nada. (refrão). Amor eu vou me declarar. Você é tudo que eu sempre quis. Eu quero acordar de manhã do teu lado e dizer. Que eu sou o homem mais feliz. (refrão). Hoje sou um homem feliz. Teu sorriso me traz paz. Você me completa. Te amo cada dia mais. A vida me ensinou. O que é valorizar. O verdadeiro amor não tem hora pra chegar. Não tenha medo de arriscar. (refrão). Amor eu vou me declarar. Você é tudo que eu sempre quis. Eu quero acordar de manhã do teu lado e dizer. Que eu sou o homem mais feliz. (refrão)      1\n",
              "A fome que assola o mundo corrupto. É a mesma que te faz sofrer. Protestos gestos nações sem teto. Procurando um lugar pra se esconder. No tropeço conquisto o apreço. Daquela gente que não me quer bem. Por isso me olho no espelho e sustento. Naqueles que só fazem o bem. Então eu sigo em frente. A vida se encarrega da missão. Pensando diferente levando o som pra mente. Voltar atrás jamais querer encontrar. Um motivo pra explicar. Que eu vou dar um giro no mundo. Buscar um lugar ao sol. Um lugar ao sol, meu lugar ao sol. Tentar, achar, buscar, querer você. Encontrar você                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
              "Name: Lyric, Length: 164789, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL3Jh3gv5NQg",
        "outputId": "88cc068e-c878-48a0-f510-f393fee8e9b8"
      },
      "source": [
        "df_lyrics['Idiom'].fillna(value = 'Unknown', inplace = True)\n",
        "df_lyrics['Idiom'].value_counts(dropna = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ENGLISH           114723\n",
              "PORTUGUESE         85085\n",
              "SPANISH             4812\n",
              "Unknown             3109\n",
              "ITALIAN              626\n",
              "FRENCH               471\n",
              "GERMAN               314\n",
              "KINYARWANDA           88\n",
              "ICELANDIC             47\n",
              "SWEDISH               27\n",
              "FINNISH               24\n",
              "INDONESIAN            17\n",
              "ESTONIAN              12\n",
              "GALICIAN              12\n",
              "IRISH                  9\n",
              "HAITIAN_CREOLE         9\n",
              "DANISH                 9\n",
              "BASQUE                 8\n",
              "NORWEGIAN              7\n",
              "CROATIAN               7\n",
              "TAGALOG                7\n",
              "SUNDANESE              6\n",
              "CATALAN                6\n",
              "DUTCH                  5\n",
              "SWAHILI                5\n",
              "MALAY                  4\n",
              "RUSSIAN                4\n",
              "SERBIAN                3\n",
              "NYANJA                 2\n",
              "SESOTHO                2\n",
              "TURKISH                2\n",
              "CEBUANO                2\n",
              "JAPANESE               2\n",
              "MALAGASY               2\n",
              "KURDISH                2\n",
              "ARABIC                 2\n",
              "SLOVENIAN              1\n",
              "SLOVAK                 1\n",
              "CZECH                  1\n",
              "AFRIKAANS              1\n",
              "WELSH                  1\n",
              "HUNGARIAN              1\n",
              "KOREAN                 1\n",
              "BOSNIAN                1\n",
              "HMONG                  1\n",
              "POLISH                 1\n",
              "GANDA                  1\n",
              "ROMANIAN               1\n",
              "Name: Idiom, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH6-Udscz2Ba",
        "outputId": "589d50b1-e53b-4e04-8fab-1977f3b05ee4"
      },
      "source": [
        "df_lyrics.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ALink    0\n",
              "SName    0\n",
              "SLink    0\n",
              "Lyric    0\n",
              "Idiom    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 401
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83LCg1NAbJyI"
      },
      "source": [
        "# **Checking and removing duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "rxBuT2qWbPk7",
        "outputId": "6aacc782-9bed-4248-b59d-acbd45110def"
      },
      "source": [
        "# dfObj[dfObj.duplicated(['Name'])]\n",
        "df_lyrics_final = df_lyrics\n",
        "df_lyrics_final.drop_duplicates(subset = ['Lyric'], inplace = True)\n",
        "df_lyrics_final[df_lyrics_final.duplicated()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ALink</th>\n",
              "      <th>SName</th>\n",
              "      <th>SLink</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>Idiom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [ALink, SName, SLink, Lyric, Idiom]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qpOtFO5_uhv"
      },
      "source": [
        "# **Table to use for the algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5igTkHk_3yt",
        "outputId": "dd0ddd9d-ae93-449e-c3cc-c01a199b73df"
      },
      "source": [
        "df_lyrics_final.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ALink    0\n",
              "SName    0\n",
              "SLink    0\n",
              "Lyric    0\n",
              "Idiom    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eWsTL0GC2sh"
      },
      "source": [
        "# Instrumental                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         592\n",
        "# instrumental                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         265\n",
        "# [Instrumental]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        66\n",
        "# (Instrumental)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        66\n",
        "# (instrumental) \n",
        "leave = ['Instrumental', 'instrumental', '[Instrumental]', '(Instrumental)', '(instrumental)']\n",
        "df_lyrics_final = df_lyrics_final[~df_lyrics_final['Lyric'].isin(leave)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "253ZII-4_WXT",
        "outputId": "53904aea-8e8e-4c49-c893-19817b206fff"
      },
      "source": [
        "df_lyrics_final.rename(columns = {'ALink':'Artist', 'SName':'Song'}, inplace = True)\n",
        "df_lyrics_final['Artist'] = df_lyrics_final['Artist'].map(lambda x: x.lstrip('/').rstrip('/'))\n",
        "df_lyrics_final.reset_index(inplace = True)\n",
        "df_lyrics_final.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Song</th>\n",
              "      <th>SLink</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>Idiom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10000-maniacs</td>\n",
              "      <td>More Than This</td>\n",
              "      <td>/10000-maniacs/more-than-this.html</td>\n",
              "      <td>I could feel at the time. There was no way of ...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10000-maniacs</td>\n",
              "      <td>Because The Night</td>\n",
              "      <td>/10000-maniacs/because-the-night.html</td>\n",
              "      <td>Take me now, baby, here as I am. Hold me close...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>10000-maniacs</td>\n",
              "      <td>These Are Days</td>\n",
              "      <td>/10000-maniacs/these-are-days.html</td>\n",
              "      <td>These are. These are days you'll remember. Nev...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10000-maniacs</td>\n",
              "      <td>A Campfire Song</td>\n",
              "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
              "      <td>A lie to say, \"O my mountain has coal veins an...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>10000-maniacs</td>\n",
              "      <td>Everyday Is Like Sunday</td>\n",
              "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
              "      <td>Trudging slowly over wet sand. Back to the ben...</td>\n",
              "      <td>ENGLISH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...    Idiom\n",
              "0      0  ...  ENGLISH\n",
              "1      1  ...  ENGLISH\n",
              "2      2  ...  ENGLISH\n",
              "3      3  ...  ENGLISH\n",
              "4      4  ...  ENGLISH\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 405
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzOo6LNmDNae"
      },
      "source": [
        "df_lyrics_final.to_csv('/content/drive/MyDrive/df_lyrics_final.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVRx6_s_nHrk"
      },
      "source": [
        "# Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-M33eahbCJAd",
        "outputId": "beea4ba5-e7d1-4958-d0d1-3f43ae2332c8"
      },
      "source": [
        "#Remove punctuation\n",
        "def punct(lyrics):\n",
        "  return lyrics.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "punct('Hello, Nuno, wher\"e is the Pizza??!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello Nuno where is the Pizza'"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUxvhQTWDuul",
        "outputId": "488d23ff-e2f8-499b-d7b6-d857b98facb6"
      },
      "source": [
        "#Dict max_values  TODO: to check\n",
        "def max_dict(dicto):\n",
        "  all_values = dicto.items()\n",
        "  return max(all_values) \n",
        "\n",
        "test = {'Hey':6, 'tOOOP':9, 'GGOGO':9}\n",
        "max_dict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tOOOP', 9)"
            ]
          },
          "metadata": {},
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLuO9C-0U45u",
        "outputId": "f4b34232-e3c2-4958-8e14-37a28c0b950e"
      },
      "source": [
        "#Grab the index of the most similar song\n",
        "def dict_sum(dicto2):\n",
        "    return max(list(dicto2.items()), key=lambda x: sum(x[1]))[0]\n",
        "test2 = {1: [2, 21], 2: [1, 22], 3: [0, 24], 4: [2, 18], 5: [2, 29], 6: [4, 16], 7: [0, 13], 8: [1, 20], 9: [1, 20], 10: [2, 28], 11: [1, 32], 12: [0, 26], 13: [3, 27], 14: [1, 34], 15: [3, 25], 16: [2, 26], 17: [0, 28], 18: [0, 21], 19: [3, 23], 20: [272, 181], 21: [3, 26], 22: [0, 20]}\n",
        "dict_sum(test2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgLVqjE0nKnx"
      },
      "source": [
        "#Function to call to loop into the DB\n",
        "max_similar = 0\n",
        "similar_w_unique = 0\n",
        "similar_w_not_unique = 0\n",
        "def lyrics_comparator(lyrics_one, lyrics_two):\n",
        "  global max_similar, similar_w_unique, similar_w_not_unique\n",
        "  df_lyrics = pd.DataFrame(range(0,300),columns={'song1'}) # creating DF to compare\n",
        "  df_lyrics['song1'] = pd.DataFrame(lyrics_one.split()) \n",
        "  df_lyrics['song2'] = pd.DataFrame(lyrics_two.split()) # adding another column with song frm DF\n",
        "  df_lyrics.rename(columns={0:'song1'},inplace=True) # renaming column\n",
        "  #Creating column comparison after putting all words lower\n",
        "  df_lyrics['song1'] = df_lyrics['song1'].apply(lambda item: item.lower() if isinstance(item,str) else item)\n",
        "  df_lyrics['song2'] = df_lyrics['song2'].apply(lambda item: item.lower()if isinstance(item,str) else item)\n",
        "  df_lyrics['equal'] = df_lyrics[['song1','song2']].apply(lambda item:  item[0] == item[1] ,axis=1) #1 if str(item[0]) == str(item[1]) else 0,axis=1)#item[0] == item[1] ,axis=1)\n",
        "  values1 = df_lyrics['song1'].value_counts(dropna=True).keys().tolist()\n",
        "  counts1 = df_lyrics['song1'].value_counts(dropna=True).tolist()\n",
        "  value_dict_lyrics1 = dict(zip(values1, counts1))\n",
        "  values2 = df_lyrics['song2'].value_counts(dropna=True).keys().tolist()\n",
        "  counts2 = df_lyrics['song2'].value_counts(dropna=True).tolist()\n",
        "  value_dict_lyrics2 = dict(zip(values2, counts2))\n",
        "  #Creating the lists to check the similars words but not uniques\n",
        "  list_song1 = list(lyrics_one.split())\n",
        "  list_song2 = list(lyrics_two.split())\n",
        "  dict3 = [w for w in list_song1 if w in list_song2]\n",
        "  #Obtaining the lenght to show percentage\n",
        "  song1_len = df_lyrics['song1'].count() \n",
        "  song2_len = df_lyrics['song2'].count()\n",
        "  #Creating a dict to see same word in disorder\n",
        "  dict2 = [i for i in value_dict_lyrics1.keys() if i in value_dict_lyrics2.keys()]\n",
        "  # dict2 = {i for i,j in value_dict_lyrics1.items() if i in value_dict_lyrics2}\n",
        "  #print(\"similar words\",dict2)\n",
        "  #Variable to use outside the function\n",
        "  similar_w_unique = len(dict2)\n",
        "  similar_w_not_unique = len(dict3)\n",
        "  max_similar = df_lyrics['equal'].sum()\n",
        "  #Temporary to check\n",
        "  #Rapport to return to the user\n",
        "  return  similar_w_unique,similar_w_not_unique,max_similar, value_dict_lyrics1, value_dict_lyrics2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x79cS2TOnPyg"
      },
      "source": [
        "lyrics_comparator(df_lyrics_final['Lyric'][0], df_lyrics_final['Lyric'][22])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zMLIc3DWgvo"
      },
      "source": [
        "# Function for the report\n",
        "max_similar = 0\n",
        "similar_w_unique = 0\n",
        "similar_w_not_unique = 0\n",
        "def lyrics_report(lyrics_one, lyrics_two):\n",
        "  global max_similar, similar_w_unique, similar_w_not_unique\n",
        "  df_lyrics = pd.DataFrame(range(0,300),columns={'song1'}) # creating DF to compare\n",
        "  df_lyrics['song1'] = pd.DataFrame(lyrics_one.split()) \n",
        "  df_lyrics['song2'] = pd.DataFrame(lyrics_two.split()) # adding another column with song frm DF\n",
        "  df_lyrics.rename(columns={0:'song1'},inplace=True) # renaming column\n",
        "  #Creating column comparison after putting all words lower\n",
        "  df_lyrics['song1'] = df_lyrics['song1'].apply(lambda item: item.lower() if isinstance(item,str) else item)\n",
        "  df_lyrics['song2'] = df_lyrics['song2'].apply(lambda item: item.lower()if isinstance(item,str) else item)\n",
        "  df_lyrics['equal'] = df_lyrics[['song1','song2']].apply(lambda item:  item[0] == item[1] ,axis=1) #1 if str(item[0]) == str(item[1]) else 0,axis=1)#item[0] == item[1] ,axis=1)\n",
        "  \n",
        "  #print(df_lyrics['song1'])\n",
        "  #print(df_lyrics['song2'])\n",
        "  #print(\"words in your song1\",\"\\n\",df_lyrics['song1'].value_counts())\n",
        "  #print(\"words in the compared song2\",\"\\n\",df_lyrics['song2'].value_counts())\n",
        "  #preparing to build the dict with value_counts()\n",
        "  values1 = df_lyrics['song1'].value_counts(dropna=True).keys().tolist()\n",
        "  counts1 = df_lyrics['song1'].value_counts(dropna=True).tolist()\n",
        "  value_dict_lyrics1 = dict(zip(values1, counts1))\n",
        "  values2 = df_lyrics['song2'].value_counts(dropna=True).keys().tolist()\n",
        "  counts2 = df_lyrics['song2'].value_counts(dropna=True).tolist()\n",
        "  value_dict_lyrics2 = dict(zip(values2, counts2))\n",
        "  #Creating the lists to check the similars words but not uniques\n",
        "  list_song1 = list(lyrics_one.split())\n",
        "  list_song2 = list(lyrics_two.split())\n",
        "  dict3 = [w for w in list_song1 if w in list_song2]\n",
        "  # print(\"TO CHECK\",list_song1)\n",
        "  # print(\"TO CHECK\",list_song2)\n",
        "  # print(\"TO CHECK\",dict3)\n",
        "  #Obtaining the lenght to show percentage\n",
        "  song1_len = df_lyrics['song1'].count() \n",
        "  song2_len = df_lyrics['song2'].count()\n",
        "  #Creating a dict to see same word in disorder\n",
        "  dict2 = [i for i in value_dict_lyrics1.keys() if i in value_dict_lyrics2.keys()]\n",
        "  # dict2 = {i for i,j in value_dict_lyrics1.items() if i in value_dict_lyrics2}\n",
        "  #Variable to use outside the function\n",
        "  similar_w_unique = len(dict2)\n",
        "  # print(\"len dict2=\",len(dict2))\n",
        "  similar_w_not_unique = len(dict3)\n",
        "  # print(\"len dict3=\",len(dict3))\n",
        "  max_similar = df_lyrics['equal'].sum()\n",
        "  #Temporary to check\n",
        "  #print(counts1,values1)\n",
        "  #print(counts2,values2)\n",
        "  #print(dict2)\n",
        "  #Rapport to return to the user\n",
        "  print(\"The closest lyrical song contains\",song2_len,\"words\")\n",
        "  print(df_lyrics['equal'].sum(),\"words are at the exact same position\")\n",
        "  # print(\"similar unique words\",dict2)\n",
        "  print(round((df_lyrics['equal'].sum()/song2_len)*100,2), \"% of your song is similar\")\n",
        "  print(\"% of same words used\",round((len(dict3)/len(list_song2)) * 100, 2))\n",
        "  # print(\"These are the words that are most repeated: \",)\n",
        "  # print(\"please find below the list of the words present in your song with the number of appearence\")\n",
        "  print(value_dict_lyrics1,value_dict_lyrics2)\n",
        "  return similar_w_unique, similar_w_not_unique, max_similar, value_dict_lyrics1, value_dict_lyrics2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FdaBD1AR57c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9259a155-eb0f-4e5a-beff-6d639dfcde68"
      },
      "source": [
        "#function to loop into lyrics column of the dataframe\n",
        "lyrics_one=df_lyrics_final['Lyric'][1320]\n",
        "#lyrics_comparator(lyrics_one, lyrics_two)\n",
        "final_dict = {}\n",
        "for i in range(1, 1000): #len(df_lyrics_final['Lyric'])):\n",
        "  lyrics_comparator(punct(lyrics_one), punct(df_lyrics_final['Lyric'][i]))\n",
        "  final_dict[i] = [max_similar,similar_w_unique, similar_w_not_unique]\n",
        "  #values1 = df_lyrics['song1'].value_counts(dropna=True).keys().tolist()\n",
        "  #counts1 = df_lyrics['song1'].value_counts(dropna=True).tolist()\n",
        "  #final_dict = dict(zip(values1, counts1))\n",
        "#print(final_dict)\n",
        "lyrics_report(punct(lyrics_one), punct(df_lyrics_final['Lyric'][dict_sum(final_dict)]))\n",
        "print(df_lyrics_final.iloc[dict_sum(final_dict)][['Artist','Song']])\n",
        "link = df_lyrics_final.iloc[dict_sum(final_dict)][['SLink']] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The closest lyrical song contains 300 words\n",
            "2 words are at the exact same position\n",
            "0.67 % of your song is similar\n",
            "% of same words used 18.35\n",
            "{'and': 14, 'you': 11, 'the': 8, 'lights': 7, 'our': 6, 'of': 6, 'city': 6, 'like': 6, 'dance': 5, 'fall': 5, 'all': 5, 'control': 4, 'as': 4, 'kiss': 4, 'from': 4, 'rain': 4, 'to': 4, 'explode': 4, 'a': 3, 'hearts': 3, 'pain': 3, 'broken': 3, 'me': 3, 'stars': 3, 'death': 2, 'well': 2, 'see': 2, 'us': 2, 'apart': 2, 'nights': 2, 'your': 2, 'i': 2, 'upon': 2, 'while': 2, 'show': 2, 'steal': 2, 'debutants': 2, 'that': 2, 'die': 2, 'burn': 2, 'ill': 2, 'reeling': 2, 'how': 2, 'will': 2, 'more': 2, 'said': 2, 'we': 2, 'watch': 2, 'need': 2, 'floor': 1, 'part': 1, 'here': 1, 'tell': 1, 'old': 1, 'smiled': 1, 'now': 1, 'breath': 1, 'dead': 1, 'light': 1, 'should': 1, 'fear': 1, 'want': 1, 'cutting': 1, 'jumped': 1, 'before': 1, 'for': 1, 'then': 1, 'burns': 1, 'lips': 1, 'they': 1, 'would': 1, 'forth': 1, 'ourrrrr': 1, 'in': 1, 'height': 1, 'room': 1, 'velvet': 1, 'whisk': 1, 'time': 1, 'lives': 1, 'dreams': 1, 'restraining': 1, 'away': 1, 'blushed': 1, 'stay': 1, 'not': 1, 'hold': 1, 'wrists': 1, 'bite': 1, 'exploding': 1, 'glowing': 1, 'inpressed': 1, 'im': 1, 'hearrrrrrtssss': 1, 'burst': 1, 'one': 1, 'movie': 1, 'be': 1, 'feed': 1, 'bit': 1, 'has': 1, 'smile': 1, 'sky': 1, 'marks': 1, 'caress': 1, 'heartssss': 1, 'what': 1, 'my': 1, 'glamour': 1, 'if': 1, 'above': 1, 'turn': 1, 'swallow': 1, 'nothing': 1, 'blush': 1} {'i': 14, 'the': 11, 'a': 9, 'my': 8, 'it': 8, 'we': 7, 'and': 7, 'he': 6, 'in': 4, 'to': 4, 'didnt': 3, 'no': 3, 'face': 3, 'all': 3, 'im': 3, 'have': 3, 'if': 3, 'with': 3, 'by': 2, 'of': 2, 'him': 2, 'had': 2, 'up': 2, 'for': 2, 'can': 2, 'me': 2, 'over': 2, 'day': 2, 'or': 2, 'that': 2, 'were': 2, 'dont': 2, 'mind': 2, 'couldnt': 2, 'put': 2, 'said': 2, 'people': 2, 'our': 2, 'on': 2, 'not': 2, 'wouldnt': 2, 'talkin': 1, 'see': 1, 'tell': 1, 'rolls': 1, 'now': 1, 'about': 1, 'verbs': 1, 'am': 1, 'course': 1, 'curse': 1, 'homey': 1, 'stood': 1, 'sunk': 1, 'continue': 1, 'laugh': 1, 'hes': 1, 'us': 1, 'go': 1, 'let': 1, 'you': 1, 'wits': 1, 'throw': 1, 'an': 1, 'hear': 1, 'passed': 1, 'break': 1, 'rights': 1, 'week': 1, 'fuck': 1, 'fartin': 1, 'match': 1, 'fucked': 1, 'together': 1, 'review': 1, 'although': 1, 'would': 1, 'oh': 1, 'shame': 1, 'its': 1, 'ass': 1, 'dread': 1, 'decline': 1, 'board': 1, 'like': 1, 'flow': 1, 'gas': 1, 'funk': 1, 'never': 1, 'pnut': 1, 'then': 1, 'make': 1, 'human': 1, 'even': 1, 'comin': 1, 'some': 1, 'say': 1, 'funny': 1, 'place': 1, 'toots': 1, 'keep': 1, 'hidden': 1, 'funky': 1, 'bare': 1, 'grab': 1, 'while': 1, 'when': 1, 'scores': 1, 'minute': 1, 'so': 1, 'country': 1, 'kick': 1, 'herb': 1, 'fucking': 1, 'bit': 1, 'head': 1, 'there': 1, 'slick': 1, 'sometimes': 1, 'any': 1, 'apply': 1, 'get': 1, 'who': 1, 'proceed': 1, 'steady': 1, 'isnt': 1, 'shit': 1, 'music': 1, 'looked': 1, 'joint': 1, 'guns': 1, 'uhuh': 1, 'could': 1, 'thought': 1, 'drop': 1, 'just': 1, 'uh': 1, 'last': 1, 'club': 1, 'stay': 1, 'verse': 1, 'tummy': 1, 'chads': 1, 'dead': 1, 'rather': 1, 'whats': 1, 'probably': 1, 'doin': 1, 'another': 1, 'sticker': 1, 'locks': 1, 'keel': 1, 'many': 1, 'ok': 1, 'limerick': 1, 'every': 1, 'firmly': 1, 'real': 1, 'what': 1, 'matter': 1, 'but': 1, 'night': 1, 'id': 1, 'one': 1, 'others': 1, 'way': 1, 'junk': 1, 'will': 1, 'from': 1, 'bow': 1, 'really': 1, 'better': 1, 'rehearsed': 1, 'care': 1, 'whether': 1, 'loose': 1, 'different': 1, 'trip': 1, 'road': 1, 'hide': 1, 'sport': 1, 'chill': 1, 'lose': 1, 'ride': 1, 'till': 1, 'roughneck': 1, 'cop': 1, 'stage': 1, 'nothing': 1, 'through': 1, 'nick': 1, 'know': 1, 'shaved': 1}\n",
            "Artist                 311\n",
            "Song      Offbeat Bare-ass\n",
            "Name: 388, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ITLHjYm2lXp"
      },
      "source": [
        "# ###### Function to filter the DF. \n",
        "# max_similar = 0\n",
        "# similar_w_unique = 0\n",
        "# # similar_w_not_unique = 0\n",
        "# def lyrics_filter(lyrics_one, lyrics_two):\n",
        "#   global similar_w_not_unique\n",
        "#   #df_lyrics = pd.DataFrame(range(0,300),columns={'song1'}) # creating DF to compare\n",
        "#   #df_lyrics['song1'] = pd.DataFrame(lyrics_one.split()) \n",
        "#   #df_lyrics['song2'] = pd.DataFrame(lyrics_two.split()) # adding another column with song frm DF\n",
        "#   #df_lyrics.rename(columns={0:'song1'},inplace=True) # renaming column\n",
        "#   #Creating column comparison after putting all words lower\n",
        "#   #df_lyrics['song1'] = df_lyrics['song1'].apply(lambda item: item.lower() if isinstance(item,str) else item)\n",
        "#   #df_lyrics['song2'] = df_lyrics['song2'].apply(lambda item: item.lower()if isinstance(item,str) else item)\n",
        "#   #df_lyrics['equal'] = df_lyrics[['song1','song2']].apply(lambda item:  item[0] == item[1] ,axis=1) #1 if str(item[0]) == str(item[1]) else 0,axis=1)#item[0] == item[1] ,axis=1)\n",
        "#   #values1 = df_lyrics['song1'].value_counts(dropna=True).keys().tolist()\n",
        "#   #counts1 = df_lyrics['song1'].value_counts(dropna=True).tolist()\n",
        "#   #value_dict_lyrics1 = dict(zip(values1, counts1))\n",
        "#   #values2 = df_lyrics['song2'].value_counts(dropna=True).keys().tolist()\n",
        "#   #counts2 = df_lyrics['song2'].value_counts(dropna=True).tolist()\n",
        "#   #value_dict_lyrics2 = dict(zip(values2, counts2))\n",
        "#   #Creating the lists to check the similars words but not uniques\n",
        "#   list_song1 = list(lyrics_one.split())\n",
        "#   list_song2 = list(lyrics_two.split())\n",
        "#   dict3 = [w for w in list_song1 if w in list_song2]\n",
        "#   #Obtaining the lenght to show percentage\n",
        "#   #song1_len = df_lyrics['song1'].count() \n",
        "#   #song2_len = df_lyrics['song2'].count()\n",
        "#   #Creating a dict to see same word in disorder\n",
        "#   #dict2 = [i for i in value_dict_lyrics1.keys() if i in value_dict_lyrics2.keys()]\n",
        "#   # dict2 = {i for i,j in value_dict_lyrics1.items() if i in value_dict_lyrics2}\n",
        "#   #print(\"similar words\",dict2)\n",
        "#   #Variable to use outside the function\n",
        "#   #similar_w_unique = len(dict2)\n",
        "#   similar_w_not_unique = len(dict3)\n",
        "#   #max_similar = df_lyrics['equal'].sum()\n",
        "#   #Temporary to check\n",
        "#   #Rapport to return to the user\n",
        "#   return  similar_w_not_unique\n",
        "\n",
        "# filter_dict = {i: lyrics_comparator(punct(lyrics_one), punct(df_lyrics_final['Lyric'][i])) for i in range(1, len(df_lyrics_final['Lyric']))}\n",
        "# # for i in range(1, len(df_lyrics_final['Lyric'])):\n",
        "# #   val = lyrics_comparator(punct(lyrics_one), punct(df_lyrics_final['Lyric'][i]))\n",
        "# #   # filter_dict[i] = [similar_w_not_unique]\n",
        "# # filter_dict = df_lyrics_final['Lyric']\n",
        "\n",
        "# print(filter_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}